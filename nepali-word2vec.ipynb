{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea754f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:13:18.858417Z",
     "iopub.status.busy": "2021-10-13T12:13:18.852985Z",
     "iopub.status.idle": "2021-10-13T12:15:10.094778Z",
     "shell.execute_reply": "2021-10-13T12:15:10.095950Z",
     "shell.execute_reply.started": "2021-10-13T11:03:53.130258Z"
    },
    "papermill": {
     "duration": 111.261318,
     "end_time": "2021-10-13T12:15:10.096966",
     "exception": false,
     "start_time": "2021-10-13T12:13:18.835648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file .......\n",
      "Total number of lines in text file 5891518\n",
      "Time required to read the file 101.750362739\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~IMPORTING THE DATASET~~~~~~~~~~~~~~~~\n",
    "start = time.process_time() \n",
    "print(\"Reading the file .......\")\n",
    "f = open(\"../input/nepdata/clean.txt\" , encoding= 'utf-8' , buffering= 10000)\n",
    "lines = f.read().strip().split(u\"।\")\n",
    "sentences = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in lines]\n",
    "f.close()\n",
    "print(f\"Total number of lines in text file {len(sentences)}\")\n",
    "print(f\"Time required to read the file {time.process_time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2304c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:15:10.185924Z",
     "iopub.status.busy": "2021-10-13T12:15:10.184840Z",
     "iopub.status.idle": "2021-10-13T12:15:20.665863Z",
     "shell.execute_reply": "2021-10-13T12:15:20.665286Z",
     "shell.execute_reply.started": "2021-10-13T11:05:53.217865Z"
    },
    "papermill": {
     "duration": 10.560131,
     "end_time": "2021-10-13T12:15:20.666032",
     "exception": false,
     "start_time": "2021-10-13T12:15:10.105901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowballstemmer\r\n",
      "  Downloading snowballstemmer-2.1.0-py2.py3-none-any.whl (93 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 93 kB 665 kB/s \r\n",
      "\u001b[?25hInstalling collected packages: snowballstemmer\r\n",
      "Successfully installed snowballstemmer-2.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3703412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:15:20.703793Z",
     "iopub.status.busy": "2021-10-13T12:15:20.702635Z",
     "iopub.status.idle": "2021-10-13T12:39:29.276572Z",
     "shell.execute_reply": "2021-10-13T12:39:29.277254Z",
     "shell.execute_reply.started": "2021-10-13T11:21:11.348386Z"
    },
    "papermill": {
     "duration": 1448.601596,
     "end_time": "2021-10-13T12:39:29.277663",
     "exception": false,
     "start_time": "2021-10-13T12:15:20.676067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE FOR 0.0 LAKHS LINES\n",
      "DONE FOR 1.0 LAKHS LINES\n",
      "DONE FOR 2.0 LAKHS LINES\n",
      "DONE FOR 3.0 LAKHS LINES\n",
      "DONE FOR 4.0 LAKHS LINES\n",
      "DONE FOR 5.0 LAKHS LINES\n",
      "DONE FOR 6.0 LAKHS LINES\n",
      "DONE FOR 7.0 LAKHS LINES\n",
      "DONE FOR 8.0 LAKHS LINES\n",
      "DONE FOR 9.0 LAKHS LINES\n",
      "DONE FOR 10.0 LAKHS LINES\n",
      "DONE FOR 11.0 LAKHS LINES\n",
      "DONE FOR 12.0 LAKHS LINES\n",
      "DONE FOR 13.0 LAKHS LINES\n",
      "DONE FOR 14.0 LAKHS LINES\n",
      "DONE FOR 15.0 LAKHS LINES\n",
      "DONE FOR 16.0 LAKHS LINES\n",
      "DONE FOR 17.0 LAKHS LINES\n",
      "DONE FOR 18.0 LAKHS LINES\n",
      "DONE FOR 19.0 LAKHS LINES\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~ Getting the dataset ready for training word2vec model ~~~~~~~~~~\n",
    "import re\n",
    "import snowballstemmer \n",
    "mainlist = list()\n",
    "class Main_Data_list:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.stop_word_list = []\n",
    "        self.mainlist = []\n",
    "        \n",
    "        a_file = open(\"../input/stopwords/stopwords.txt\", \"r\" ,encoding= 'utf-8')\n",
    "        for line in a_file:\n",
    "            stripped_line = line.strip()\n",
    "            self.stop_word_list.append(stripped_line)\n",
    "        a_file.close()\n",
    "        \n",
    "        self.stemmer = snowballstemmer.NepaliStemmer()\n",
    "        \n",
    "        \n",
    "    def simple_tokenizer(self,text) -> list:\n",
    "        \n",
    "        line = re.sub('[।]',\"\", text)\n",
    "        \n",
    "        devanagari_range = r'[\\u0900-\\u097F\\\\]'\n",
    "        def getDevanagariCharCount(token):\n",
    "            return len(list(filter(lambda char: re.match(devanagari_range, char), (char for char in token))))\n",
    "        def isDevanagari(token):\n",
    "            return True if getDevanagariCharCount(token) >= len(token)/2 else False \n",
    "\n",
    "        tokens = list(filter(lambda t: isDevanagari(t), line.split(\" \")))\n",
    "        return tokens\n",
    "\n",
    "    def get(self):\n",
    "        for i,line in enumerate(self.dataset[0:2000000]):\n",
    "            \n",
    "            wordsList = self.simple_tokenizer(line)\n",
    "            words = [w for w in wordsList if not w in self.stop_word_list]\n",
    "            words  = self.stemmer.stemWords(words)\n",
    "            if len(words) > 3:\n",
    "                self.mainlist.append(words)\n",
    "            if i % 100000 == 0:\n",
    "                print(f\"DONE FOR {i/100000} LAKHS LINES\")\n",
    "        return self.mainlist\n",
    "                \n",
    "final = Main_Data_list(sentences)\n",
    "mainlist = final.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4ebd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:39:29.316281Z",
     "iopub.status.busy": "2021-10-13T12:39:29.315592Z",
     "iopub.status.idle": "2021-10-13T12:43:11.874361Z",
     "shell.execute_reply": "2021-10-13T12:43:11.874983Z",
     "shell.execute_reply.started": "2021-10-13T11:39:13.508373Z"
    },
    "papermill": {
     "duration": 222.580202,
     "end_time": "2021-10-13T12:43:11.875219",
     "exception": false,
     "start_time": "2021-10-13T12:39:29.295017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103822776, 122202960)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    vector_size = 200 ,\n",
    "    window=  5,\n",
    "    min_count=2,\n",
    "    workers= 4\n",
    ")\n",
    "\n",
    "model.build_vocab(mainlist, progress_per=1000 )\n",
    "\n",
    "model.train(mainlist, total_examples= model.corpus_count, epochs= model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd13ab5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:43:11.912746Z",
     "iopub.status.busy": "2021-10-13T12:43:11.911981Z",
     "iopub.status.idle": "2021-10-13T12:43:12.283813Z",
     "shell.execute_reply": "2021-10-13T12:43:12.284900Z",
     "shell.execute_reply.started": "2021-10-13T11:41:59.007521Z"
    },
    "papermill": {
     "duration": 0.393206,
     "end_time": "2021-10-13T12:43:12.285213",
     "exception": false,
     "start_time": "2021-10-13T12:43:11.892007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('लेकसाइड', 0.7085685729980469),\n",
       " ('जमल', 0.7031379342079163),\n",
       " ('बानेश्वर', 0.6600849628448486),\n",
       " ('सामाखुसी', 0.6546829342842102),\n",
       " ('न्युरोड', 0.6507934927940369),\n",
       " ('गोंगबु', 0.6498370170593262),\n",
       " ('बागबजार', 0.6398636102676392),\n",
       " ('कलं', 0.6395446062088013),\n",
       " ('हाइसन्चो\\n', 0.6294294595718384),\n",
       " ('घण्टाघर', 0.6282877922058105)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('ठमेल')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a50da0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:43:12.354532Z",
     "iopub.status.busy": "2021-10-13T12:43:12.353152Z",
     "iopub.status.idle": "2021-10-13T12:43:12.387372Z",
     "shell.execute_reply": "2021-10-13T12:43:12.388443Z",
     "shell.execute_reply.started": "2021-10-13T12:12:04.069999Z"
    },
    "papermill": {
     "duration": 0.072962,
     "end_time": "2021-10-13T12:43:12.388763",
     "exception": false,
     "start_time": "2021-10-13T12:43:12.315801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\nचितवन', 0.6697115898132324),\n",
       " ('भरतपुर', 0.6169254183769226),\n",
       " ('रूपन्देही', 0.5702300071716309),\n",
       " ('सौराहा', 0.5635057687759399),\n",
       " ('रत्ननगर', 0.5632916688919067),\n",
       " ('पोखरा', 0.5580011010169983),\n",
       " ('कास्', 0.5571740865707397),\n",
       " ('काभ्रे', 0.553877055644989),\n",
       " ('पटिहानी', 0.548678994178772),\n",
       " ('नारायणगढ', 0.5401238799095154)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('चितवन')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae4dff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T12:43:12.459692Z",
     "iopub.status.busy": "2021-10-13T12:43:12.458561Z",
     "iopub.status.idle": "2021-10-13T12:43:13.743704Z",
     "shell.execute_reply": "2021-10-13T12:43:13.743023Z"
    },
    "papermill": {
     "duration": 1.323003,
     "end_time": "2021-10-13T12:43:13.743875",
     "exception": false,
     "start_time": "2021-10-13T12:43:12.420872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"nepaliW2V_5Million.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1807.562388,
   "end_time": "2021-10-13T12:43:17.369040",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-13T12:13:09.806652",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
